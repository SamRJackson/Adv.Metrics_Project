---
title: "R Notebook"
output: html_notebook
---

# Packages.
_uncomment the first line if the chunk doesn't run_
```{r}
#install.package("leaps")
#install.packages("ggplot2")
#install.packages("dplyr")
library(readxl)
library(dplyr)
library(ggplot2)
library(leaps)
```

# Loading in the dataset.
```{r}
load("C:/Users/Sam/Desktop/Adv.Metrics_Project-main/Data/CrimeData.RData")
```

# Variable of interest selection.
We start by keeping a wide selection of potential explanatory variables. Choice of variables was based on model specifications in the existing literature around crime. 
```{r}
variables_chosen <- c("communityname","state","population","PopDens","householdsize","PctFam2Par","racepctblack","racePctHisp","agePct16t24","perCapInc","pctWSocSec","pctWInvInc","PctPopUnderPov","PctNotHSGrad","PctUnemployed","ViolentCrimesPerPop","nonViolPerPop")
colnames(concat_test)<-gsub(":","",colnames(concat_test))# remove semicolons from names
concat_dropped <- concat_test[variables_chosen]
```

# Cleaning the datatset
```{r}
is.data.frame(concat_dropped)#test dataframe ok
i=c(3:17) #Select variables to turn into numeric
concat_dropped[ , i] <- apply(concat_dropped[ , i], 2,
                    function(x) as.numeric(as.character(x)))#convert relevant variables in numeric
sapply(concat_dropped, class) #check ok
concat_dropped$crimes=concat_dropped$ViolentCrimesPerPop + concat_dropped$nonViolPerPop #create dependent variable
concat_wo_na= na.omit(concat_dropped)#Drop NA statistics on drops
```

# Using subset selection and Bayesian Information Criteria to select variables
```{r}
drops <- c("communityname", "state", "nonViolPerPop","ViolentCrimesPerPop")
subselect_sample <- select(concat_wo_na,-all_of(drops))
subselect_res <- regsubsets(crimes~., data = subselect_sample, nvmax = 9, method = "forward")

summary(subselect_res)
subselect_sums <- summary(subselect_res)
data.frame(
  Adj.R2 = which.max(subselect_sums$adjr2),
  CP = which.min(subselect_sums$cp),
  BIC = which.min(subselect_sums$bic)
)
```

# Defining the final dataset we will use for estimation
```{r}
final_variables= c("communityname","state","PopDens","householdsize","PctFam2Par","racepctblack","racePctHisp","agePct16t24","PctPopUnderPov","PctNotHSGrad","PctUnemployed","crimes")
dataset=concat_wo_na[final_variables]
is.data.frame(dataset)#test dataframe ok
```
```{r}
library(MASS)
library(randomForest)
library(gbm)
library(glmnet)
dataset <- dataset[-communityname,state]
data(dataset) ; nobs = nrow(dataset)
set.seed(12345) ; nfold = 10
Kfold=cut(seq(1,nobs),breaks=nfold,labels=FALSE)
mse.test = matrix(0,nfold,4)

Xcol = colnames(dataset)[-12]
Xsqr = paste0("I(",Xcol,"^2)",collapse = "+")
Xcub = paste0("I(",Xcol,"^3)",collapse = "+")

fmla = paste0("crimes~(.)^2+", Xsqr,"+",Xcub)

X = model.matrix(as.formula(fmla),data = dataset)[,-1]
y = dataset[,12]

mysample = sample(1:nobs)
for (i in 1:nfold){
  cat("K-fold loop: ",i,"\r")
  test = mysample[which(Kfold == i)]
  train = mysample[which(Kfold != i)]
  
  fit.lm <- lm(crimes~.,data = dataset,subset=train)
  fit.la <- cv.glmnet(X[train,],y[train],alpha = 1)
  fit.rf <- randomForest(crimes~.,data = dataset, subset = train, mtry = 6)
  fit.bo <- gbm(crimes~.,data = dataset[train,],distribtuon = "gaussian",interaction.depth = 6)
  
  mse.test[i,1] = mean((dataset$crimes -predict(fit.lm,dataset))[-train]^2)
  mse.test[i,2] = mean((y -predict(fit.la,X,s = "lambda.min"))[-train]^2)
  mse.test[i,3] = mean((dataset$crimes -predict(fit.rf,dataset))[-train]^2)
  mse.test[i,4] = mean((dataset$crimes -predict(fit.bo,dataset))[-train]^2)
  

}
mse = colMeans(mse.test)
round(mse,digits = 2)


```








